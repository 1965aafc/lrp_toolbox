{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as     mx\n",
    "from   mxnet import nd\n",
    "from   mxnet import autograd\n",
    "from mxnet.gluon.nn.basic_layers import Activation\n",
    "\n",
    "from mxmodules import Sequential, Linear, Rect, Tanh\n",
    "import types\n",
    "\n",
    "import model_io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Layer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxlrp import dense_hybrid_forward_lrp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Dummy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ######### ##\n",
    "# GLUON MODEL #\n",
    "## ######### ##\n",
    "\n",
    "net_gl = mx.gluon.nn.HybridSequential()\n",
    "\n",
    "dense_0 = mx.gluon.nn.Dense(units=12, in_units=4, activation='tanh')\n",
    "dense_1 = mx.gluon.nn.Dense(units= 1, in_units=12)\n",
    "\n",
    "net_gl.add(dense_0)\n",
    "net_gl.add(dense_1)\n",
    "\n",
    "net_gl.collect_params().initialize(ctx=ctx)\n",
    "\n",
    "# extract variables from gluon model\n",
    "weight_0 = dense_0.weight.data()\n",
    "bias_0   = dense_0.bias.data()\n",
    "\n",
    "weight_1 = dense_1.weight.data()\n",
    "bias_1   = dense_1.bias.data()\n",
    "\n",
    "## ############## ##\n",
    "# STANDALONE MODEL #\n",
    "## ############## ##\n",
    "\n",
    "net_sta = Sequential([Linear(4, 12), Tanh(), Linear(12, 1)])\n",
    "\n",
    "net_sta.modules[0].W = weight_0.T\n",
    "net_sta.modules[0].B = bias_0\n",
    "net_sta.modules[2].W = weight_1.T\n",
    "net_sta.modules[2].B = bias_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Patch gluon gradient to LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in net_gl._children:\n",
    "    if layer.__class__.__name__ == 'Dense':\n",
    "        layer.hybrid_forward = types.MethodType(dense_hybrid_forward_lrp, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with standalone implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "\n",
      "[[  0.   1.   2.   3.]\n",
      " [  4.   5.   6.   7.]\n",
      " [  8.   9.  10.  11.]]\n",
      "<NDArray 3x4 @cpu(0)>\n",
      "\n",
      "GLUON impl:\n",
      "\n",
      "[[-0.00355378]\n",
      " [-0.02960501]\n",
      " [-0.048284  ]]\n",
      "<NDArray 3x1 @cpu(0)>\n",
      "\n",
      "[[ 0.          0.00364889 -0.00259847 -0.0046042 ]\n",
      " [-0.03007531  0.01729889 -0.00631801 -0.01051059]\n",
      " [-0.05498287  0.02882986 -0.00622151 -0.01590948]]\n",
      "<NDArray 3x4 @cpu(0)>\n",
      "\n",
      "Standalone impl:\n",
      "\n",
      "[[-0.00355378]\n",
      " [-0.02960501]\n",
      " [-0.048284  ]]\n",
      "<NDArray 3x1 @cpu(0)>\n",
      "\n",
      "[[ 0.          0.00364889 -0.00259847 -0.0046042 ]\n",
      " [-0.03007531  0.01729889 -0.00631801 -0.01051059]\n",
      " [-0.05498287  0.02882986 -0.00622151 -0.01590948]]\n",
      "<NDArray 3x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# forward and backward pass test\n",
    "X = nd.arange(12).reshape((3, 4))\n",
    "\n",
    "print('Input:')\n",
    "print(X)\n",
    "\n",
    "X.attach_grad()\n",
    "with autograd.record():\n",
    "    dense_out = net_gl(X)\n",
    "\n",
    "dense_out.backward(dense_out)\n",
    "hm_gluon = X.grad\n",
    "    \n",
    "print('\\nGLUON impl:')\n",
    "print(dense_out)\n",
    "print(hm_gluon)\n",
    "\n",
    "print('\\nStandalone impl:')\n",
    "linear_out = net_sta.forward(X)\n",
    "hm_standalone  = net_sta.lrp(linear_out)\n",
    "print(linear_out)\n",
    "print(hm_standalone)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
